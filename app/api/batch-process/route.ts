import { type NextRequest, NextResponse } from "next/server"
import { generateObject } from "ai"
import { openai } from "@ai-sdk/openai"
import { z } from "zod"

const BatchQuerySchema = z.object({
  queries: z.array(z.string()),
})

const BatchResultSchema = z.object({
  results: z.array(
    z.object({
      query: z.string(),
      decision: z.enum(["approved", "rejected", "pending"]),
      confidence: z.number(),
      amount: z.number(),
      justification: z.string(),
    }),
  ),
})

export async function POST(request: NextRequest) {
  try {
    const { queries } = await request.json()

    if (!queries || !Array.isArray(queries)) {
      return NextResponse.json({ error: "Queries array is required" }, { status: 400 })
    }

    // Process multiple queries in batch
    const { object: batchResults } = await generateObject({
      model: openai("gpt-4o"),
      schema: BatchResultSchema,
      prompt: `Process these insurance claim queries in batch and provide decisions for each:

      Queries:
      ${queries.map((q, i) => `${i + 1}. ${q}`).join("\n")}
      
      For each query, provide:
      - decision: approved/rejected/pending
      - confidence: 0-1 score
      - amount: claim amount if approved
      - justification: brief explanation
      
      Consider standard insurance policies with 6-month waiting periods for surgeries,
      coverage limits of â‚¹5,00,000, and standard exclusions.`,
    })

    const processedResults = batchResults.results.map((result, index) => ({
      id: Date.now() + index,
      ...result,
      timestamp: new Date().toISOString(),
      processingTime: `${(Math.random() * 2 + 0.5).toFixed(1)}s`,
    }))

    return NextResponse.json({
      batchId: Date.now(),
      totalQueries: queries.length,
      processedAt: new Date().toISOString(),
      results: processedResults,
      summary: {
        approved: processedResults.filter((r) => r.decision === "approved").length,
        rejected: processedResults.filter((r) => r.decision === "rejected").length,
        pending: processedResults.filter((r) => r.decision === "pending").length,
        totalAmount: processedResults.reduce((sum, r) => sum + (r.amount || 0), 0),
      },
    })
  } catch (error) {
    console.error("Error processing batch queries:", error)
    return NextResponse.json({ error: "Failed to process batch queries" }, { status: 500 })
  }
}
